{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classifier.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNNEpZgw8/G90MY+hxBmjuq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dominic-DallOsto/translational-neuromodelling-mdd/blob/master/Classifier/Classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kFYAl9OFI0q"
      },
      "source": [
        "### Classifying MDD Patients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeUGwyW6FOoW"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78kRfGmoXFxG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUwf_QI_GIdX"
      },
      "source": [
        "## Lasso\n",
        "\n",
        "The Lasso is a linear model that estimates sparse coefficients. It is useful in some contexts due to its tendency to prefer solutions with fewer non-zero coefficients, effectively reducing the number of features upon which the given solution is dependent. For this reason Lasso and its variants are fundamental to the field of compressed sensing. Under certain conditions, it can recover the exact set of non-zero coefficients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94JMEqJ0JxNQ"
      },
      "source": [
        "from sklearn import linear_model"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "fod97eTSFYq9",
        "outputId": "5dd0a274-a999-4c2e-e53c-487dc6503d64"
      },
      "source": [
        "# Run CV on Lasso classifier for alpha parameter optimisation\n",
        "# Source: https://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#sphx-glr-auto-examples-exercises-plot-cv-diabetes-py\n",
        "\n",
        "alphas = np.logspace(-4, -0.5, 30)\n",
        "tuned_parameters = [{'alpha': alphas}]\n",
        "n_folds = 5\n",
        "reg = linear_model.Lasso(alpha=0.1)\n",
        "clf = GridSearchCV(reg, tuned_parameters, cv=n_folds, refit=False)\n",
        "clf.fit(X_train, y_train)\n",
        "scores = clf.cv_results_['mean_test_score']\n",
        "scores_std = clf.cv_results_['std_test_score']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-eddafe83dd0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Source: https://scikit-learn.org/stable/auto_examples/exercises/plot_cv_diabetes.html#sphx-glr-auto-examples-exercises-plot-cv-diabetes-py\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mtuned_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'alpha'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mn_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aneWZ_EyIKnG"
      },
      "source": [
        "# Plot the CV results\n",
        "\n",
        "plt.figure().set_size_inches(8, 6)\n",
        "plt.semilogx(alphas, scores)\n",
        "\n",
        "# plot error lines showing +/- std. errors of the scores\n",
        "std_error = scores_std / np.sqrt(n_folds)\n",
        "\n",
        "plt.semilogx(alphas, scores + std_error, 'b--')\n",
        "plt.semilogx(alphas, scores - std_error, 'b--')\n",
        "\n",
        "# alpha=0.2 controls the translucency of the fill color\n",
        "plt.fill_between(alphas, scores + std_error, scores - std_error, alpha=0.2)\n",
        "\n",
        "plt.ylabel('CV score +/- std error')\n",
        "plt.xlabel('alpha')\n",
        "plt.axhline(np.max(scores), linestyle='--', color='.5')\n",
        "plt.xlim([alphas[0], alphas[-1]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeLPBVKaJsBI"
      },
      "source": [
        "## Random Forest\n",
        "\n",
        "A random forest is a meta estimator that fits a number of decision tree classifiers on various sub-samples of the dataset and uses averaging to improve the predictive accuracy and control over-fitting. The sub-sample size is controlled with the max_samples parameter if bootstrap=True (default), otherwise the whole dataset is used to build each tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTjJgQRVJtTa"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mndd4pikJ39k"
      },
      "source": [
        "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
        "clf.fit(X_train, y_train)\n",
        "preds = clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wLuLmmsKcg2"
      },
      "source": [
        "## CNN\n",
        "\n",
        "Following this tutorial: https://medium.com/techiepedia/binary-image-classifier-cnn-using-tensorflow-a3f5d6746697"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_opYLuZKefh"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCAvwxfaRgbP"
      },
      "source": [
        "train = ImageDataGenerator()\n",
        "test = ImageDataGenerator()\n",
        "\n",
        "train_dataset = train.flow_from_directory(\"C:/Users/ksbal/Desktop/CodeBasicML/PetImages/Train/\",\n",
        "                                          target_size=(150,150),\n",
        "                                          batch_size = 32,\n",
        "                                          class_mode = 'binary')\n",
        "                                         \n",
        "  test_dataset = test.flow_from_directory(\"C:/Users/ksbal/Desktop/CodeBasicML/PetImages/Test/\",\n",
        "                                          target_size=(150,150),\n",
        "                                          batch_size =32,\n",
        "                                          class_mode = 'binary')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQUVkVkETsgi"
      },
      "source": [
        "# Check your encoded class labels\n",
        "test_dataset.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXoRx2WwTyKo"
      },
      "source": [
        "model = keras.Sequential()\n",
        "\n",
        "# Convolutional layer and maxpool layer 1\n",
        "model.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(269,269,1)))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "\n",
        "# Convolutional layer and maxpool layer 2\n",
        "model.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "\n",
        "# Convolutional layer and maxpool layer 3\n",
        "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "\n",
        "# Convolutional layer and maxpool layer 4\n",
        "model.add(keras.layers.Conv2D(128,(3,3),activation='relu'))\n",
        "model.add(keras.layers.MaxPool2D(2,2))\n",
        "\n",
        "# This layer flattens the resulting image array to 1D array\n",
        "model.add(keras.layers.Flatten())\n",
        "\n",
        "# Hidden layer with 512 neurons and Rectified Linear Unit activation function \n",
        "model.add(keras.layers.Dense(512,activation='relu'))\n",
        "\n",
        "# Output layer with single neuron which gives 0 for MDD or 1 for Control\n",
        "#Here we use sigmoid activation function which makes our model output to lie between 0 and 1\n",
        "model.add(keras.layers.Dense(1,activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnnPnZ1FUd-5"
      },
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK4ntGjyUixe"
      },
      "source": [
        "#steps_per_epoch = train_imagesize/batch_size\n",
        "\n",
        "model.fit_generator(train_dataset,\n",
        "         steps_per_epoch = 250,\n",
        "         epochs = 10,\n",
        "         validation_data = test_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lib8XLP4U2vF"
      },
      "source": [
        "model.predict()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}